{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Real Time Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ORB(input_image, stored_image):\n",
    "    gray = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    orb_detector = cv2.ORB(1600, 1.3)\n",
    "    \n",
    "    (keypoints_1, descriptor_1) = orb_detector.detectAndCompute(gray,None)\n",
    "     \n",
    "    (keypoints_2, descriptor_2) = orb_detector.detectAndCompute(stored_image,None)\n",
    "    \n",
    "    brute_force = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    \n",
    "    matches_found = brute_force.match(descriptor_1, descriptor_2)\n",
    "    \n",
    "    matches_found = sorted(matches_found, key=lambda val: val.distance)\n",
    "    \n",
    "    return len(matches_found) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_image = cv2.imread('C:/Users/Vidush/Desktop/test1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, capturing = capture.read()\n",
    "    \n",
    "    frame_height, frame_width = capturing.shape[:2]\n",
    "    \n",
    "    x1_top_left = frame_width / 3\n",
    "    y1_top_left = (frame_height / 2) + (frame_height / 4)\n",
    "    x2_bottom_right = (frame_width / 3) * 2\n",
    "    y2_bottom_right = (frame_height / 2) - (frame_height / 4)\n",
    "    \n",
    "    cv2.rectangle(capturing,(x1_top_left,y1_top_left),(x2_bottom_right,y2_bottom_right),(0,0,255), 4)\n",
    "    \n",
    "    cropped_box = capturing[y2_bottom_right:y1_top_left , x1_top_left:x2_bottom_right]\n",
    "    \n",
    "    capturing = cv2.flip(capturing,1)\n",
    "    \n",
    "    matches_found = ORB(cropped_box,stored_image)\n",
    "    \n",
    "    string = \"Matches Found\" + str(matches_found)\n",
    "    cv2.putText(capturing, string, (150,400), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "    \n",
    "    set_threshold = 400\n",
    "    \n",
    "    if matches_found > set_threshold:\n",
    "        \n",
    "        cv2.rectangle(capturing,(x1_top_left,y1_top_left),(x2_bottom_right,y2_bottom_right),(0,255,0),4)\n",
    "        cv2.putText(capturing, \"Object Detected\", (200,50), *font, 1, (0,255,0), 2)\n",
    "    \n",
    "    cv2.imshow('Real-time Object Detection', capturing)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
